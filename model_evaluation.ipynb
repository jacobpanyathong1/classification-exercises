{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24131a82",
   "metadata": {},
   "source": [
    "#### Evaluate (by hand) the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2bb2a",
   "metadata": {},
   "source": [
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959cffe",
   "metadata": {},
   "source": [
    "The pred cat/actual dog value is a false positive. 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8add075",
   "metadata": {},
   "source": [
    "The pred dog/actual cat is a false negative. 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a92a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "279c8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ea1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_df= pd.read_csv('c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1c4249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect\n",
       "2  No Defect  No Defect  Defect  No Defect\n",
       "3  No Defect     Defect  Defect     Defect\n",
       "4  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ceb64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= pd.crosstab(c3_df.actual, c3_df.model1)\n",
    "model2= pd.crosstab(c3_df.actual, c3_df.model2)\n",
    "model3= pd.crosstab(c3_df.actual, c3_df.model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb02f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_ar=confusion_matrix(c3_df.actual,c3_df.model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bea638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model1</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model1     Defect  No Defect\n",
       "actual                      \n",
       "Defect          8          8\n",
       "No Defect       2        182"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d486ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_tp = model1_ar[0][0]\n",
    "model1_tn = model1_ar[1][1]\n",
    "model1_fn = model1_ar[0][1]\n",
    "model1_fp = model1_ar[1][0]\n",
    "perc_acc = (model1_tp+model1_tn)/(model1_tp+model1_tn+model1_fp+model1_fn)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2fa6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage: 95.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy percentage: {perc_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "618aebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_ar=confusion_matrix(c3_df.actual,c3_df.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b88d171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model2</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>81</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model2     Defect  No Defect\n",
       "actual                      \n",
       "Defect          9          7\n",
       "No Defect      81        103"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca395d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,   7],\n",
       "       [ 81, 103]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fab618c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_tp = model2_ar[0][0]\n",
    "model2_tn = model2_ar[1][1]\n",
    "model2_fn = model2_ar[0][1]\n",
    "model2_fp = model2_ar[1][0]\n",
    "perc_acc = (model2_tp+model2_tn)/(model2_tp+model2_tn+model2_fp+model2_fn)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16c49a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage: 56.00000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy percentage: {perc_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f235dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model3</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model3     Defect  No Defect\n",
       "actual                      \n",
       "Defect         13          3\n",
       "No Defect      86         98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d16793c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_ar=confusion_matrix(c3_df.actual,c3_df.model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d58b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_tp = model3_ar[0][0]\n",
    "model3_tn = model3_ar[1][1]\n",
    "model3_fn = model3_ar[0][1]\n",
    "model3_fp = model3_ar[1][0]\n",
    "perc_acc = (model3_tp+model3_tn)/(model3_tp+model3_tn+model3_fp+model3_fn)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "630c2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage: 55.50000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy percentage: {perc_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd64a7a",
   "metadata": {},
   "source": [
    "##### Codeup ducks - Accuracy, finding the amount of defects for the as many defects as possible and would be close to the amount of overall accuracy for total defects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b04c168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Defect    184\n",
       "Defect        16\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3_df.actual.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b3889",
   "metadata": {},
   "source": [
    "##### Recall, finding the amount of defects will reward the consumer with the paid vacation but a duck that isn't defective will be costly to the business. Only using recall will leave out a false positive but capture only postive cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "181070d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_recall = (model1_tp)/(model1_tp+model1_fn)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bec93679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f7e8974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.25"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_recall = (model2_tp)/(model2_tp+model2_fn)*100\n",
    "perc_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f04769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.25"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_recall = (model3_tp)/(model3_tp+model3_fn)*100\n",
    "perc_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc6e3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    3254\n",
       "cat    1746\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catdog_df= pd.read_csv('gives_you_paws.csv')\n",
    "catdog_df\n",
    "catdog_df.actual.value_counts() # Baseline is Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddc80c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1423,  323],\n",
       "       [ 640, 2614]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = catdog_df['actual']\n",
    "y_pred = catdog_df['model1']\n",
    "confusion_matrix(y_true, y_pred, labels=['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92fc4a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 accuracy: 80.74%\n",
      "baseline accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "catdog_df['baseline_prediction'] = 'dog'\n",
    "#Model 1 baseline accuracy\n",
    "model_accuracy = (catdog_df.model1 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model1 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cebb3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 accuracy: 63.04%\n",
      "baseline accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "#Model 2 baseline accuracy\n",
    "model_accuracy = (catdog_df.model2 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model1 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2ad1776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 accuracy: 50.96%\n",
      "baseline accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "#Model 3 baseline accuracy\n",
    "model_accuracy = (catdog_df.model3 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model1 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c8d2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model1 recall: 80.33%\n",
      " baseline recall: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Model 1 baseline recall\n",
    "subset = catdog_df[catdog_df.actual == 'dog']\n",
    "model_recall = (subset.model1 ==subset.actual).mean()\n",
    "baseline_recall = (subset.baseline_prediction == subset.actual).mean()\n",
    "#Print recall percentage\n",
    "print(f' model1 recall: {model_recall:.2%}')\n",
    "print(f' baseline recall: {baseline_recall:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e3782b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2 accuracy: 63.04%\n",
      "baseline accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "#Model 2 baseline accuracy\n",
    "model_accuracy = (catdog_df.model2 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model2 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e5923b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3 accuracy: 50.96%\n",
      "baseline accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "#Model 3 baseline accuracy\n",
    "model_accuracy = (catdog_df.model3 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model3 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "103e0312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3 accuracy: 50.96%\n",
      "baseline accuracy: 34.92%\n"
     ]
    }
   ],
   "source": [
    "subset = catdog_df[catdog_df.actual == 'cat']\n",
    "catdog_df['baseline_prediction'] = 'cat'\n",
    "model_accuracy = (catdog_df.model3 == catdog_df.actual).mean()\n",
    "baseline_accuracy = (catdog_df.baseline_prediction == catdog_df.actual).mean()\n",
    "#Print accuracy percentage\n",
    "print(f'model3 accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e7d52",
   "metadata": {},
   "source": [
    "<div class=\"myDiv\">\n",
    "  <h3>Takeaways</h3>\n",
    "    <p>a. The models that are better than the baseline are <b>Model2</b> and <b>Model3</b> </p>\n",
    "    <p>b. The model I recommend is <b>Model1</b> as the accuracy is the highest amounst all of the models from our findings. </p>\n",
    "    <p>c. The model I recommend is <b>Model1</b> as the accuracy is the highest amounst all of the models from our findings. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4113e8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8900238338440586"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(y_true, y_pred, pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "- for every time the model runs for a dog it gets it right 89 percent of the time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
